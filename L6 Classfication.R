# load data
bank.df <- read.csv("UniversalBank.csv")
#Target value is "Personl loan" which is in the middle of columns; Target value does not have to be at the end.

#set seed for reproducing the partition
set.seed(11)
a <- nrow(bank.df)

#random sample indexes
train.index <- sample(1:a, a*0.6)       #1st row to all rows
#Build training and validation set by indexing
train.df <- bank.df[train.index, ]
valid.df <- bank.df[-train.index, ]  # - means all the rest of the training data

install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)


#store the classification tree
default.ct <- rpart(Personal.Loan ~ ., data = train.df, method = "class")

#plot the tree   (ct means tree)
prp(default.ct)

#change the different type of the tree; numbers can be 0, 1, 2.....
prp(default.ct, type=1, extra=1)

#cp: complexity parameter, penalizing the size of the tree
#minsplit: the minimum number of observations that must exist in a node in order for a split to be attempted
#the combination of "cp = -1, minsplit = 1" gives me the full tree.
full.ct <- rpart(Personal.Loan ~ ., data = train.df, method = "class", control= rpart.control(cp= -1, minsplit = 1))

# Do Not try to prp(plot) a really large tree!

#maxdepth: the maximum depth of any node of the final tree, with the root node counted as depth 0.
#minbucket: the minimum number of observations in any terminal leaf node
my.ct <- rpart(Personal.Loan ~ ., data = train.df, method = "class", control = rpart.control(maxdepth = 3, minbucket = 30))
prp(my.ct, type=1, extra=1)

# classify records in the validation data.
# set argument type = "class" in predict() to generate predicted class membership.
# Otherwise, a probablity of belonging to each class
default.ct.point.pred <- predict(default.ct, valid.df, type = "class" )
default.ct.point.pred
#output has a "Levels:0 1" means factor data

library(ggplot2)
library(caret)

# generate confusion matrix for validation data
confusionMatrix(default.ct.point.pred, valid.df$Personal.Loan)   #cannot generate correct output, will get an error 

#convert into categorical data, doing the following:
confusionMatrix(default.ct.point.pred, factor(valid.df$Personal.Loan))

#in class ebay exercise
ebay.df <- read.csv("eBayAuctions.csv")
View(ebay.df)
#1. Split the data into training and validation datasets using a 65% to 35% ratio, with a seed of 333.
set.seed(333)
train.index <- sample(1:nrow(ebay.df), nrow(ebay.df)*0.65)
train.df <- ebay.df[train.index, ]
valid.df <- ebay.df[-train.index, ]
#2. Fit a classification tree using all predictors. Use the default tree generated by rpart().
#Apply this default tree on validation set and write down the confusion matrix. 
#How can you compute the accuracy based on the confusion matrix?

default2.ct <- rpart(Competitive ~ ., data = train.df, method = "class")
prp(default2.ct, type=1, extra=1)

default2.ct.point.pred <- predict(default2.ct, valid.df, type = "class" )
# generate confusion matrix for validation data
confusionMatrix(default2.ct.point.pred, factor(valid.df$Competitive))

#3 Find the accuracy of this model for training data.
default2.train.pred <- predict(default2.ct, train.df, type = "class")

confusionMatrix(default2.train.pred, factor(train.df$Competitive))

#4 Is this model practical for predicting the outcome of a new auction? 
# (HINT: Consider the availability of information about the predictors at the time of prediction.)

# No, close price is not available at the time of decision.

#5
#select vars:
selected.var <- c(1,2,3,4,6,7)  
selected.train.df <- train.df[, selected.var]

#6 can eyeball







